V1.0
采取 requests-beautifulsoup-re 的路线对http://mzitu.com/ 这个网站的图片进行爬取

吸取上一次在ivsky中遇到的问题，本程序将沿革遵守robots协议，并进行定时访问，最大限度的降低ip被封禁的概率。

并且将使用git进行同步和版本管理。

这是一个练习的小玩意儿。
This is a simple case for practicing.

存在的问题：
1，按张计数而不是按套图计数，不够直观和统计；
2，防止反爬的方法过于落后，导致运行速度很慢；
3，没有去重和保证套图完整的措施。
4，网页的排布相当有规律不需要每一页去爬取，有更好的方式。
我应当输出一个log而不是靠打印来记录日志。

V1.1
现在成为了一个勉强可用的小程序
改良：1，大大优化了等待时间；
2，现在是按页面进行爬取，一页二十四个页面，先进行收纳，在依次爬取；
3，现在增加了爬取日志，错误日志和已完成日志，更好的观察爬取过程和结果；
4，针对大部分规律排布的页面采用了两种爬取手法，默认情况下的方法每访问服务器一次就可以下载一张图片，大大加快速度和节约流量；后来鉴于不按规律的排布的页面太多无法在日后手动完成，保留了V1.0中相对较慢的方法。
不足：
1，错误信息不够直观；
2，缺少进度提示；
3，由于网站不断更新，页面的数量和内容不断变化，每一次爬取后，下一次不可在简单的继续；
4，反爬手段落后。